{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my regions are specified by the Califonria Fire Science Consortium https://www.cafiresci.org/northern-california\n",
    "\n",
    "metadata on noaa stations https://www.ncei.noaa.gov/access/homr/reports/mshr\n",
    "\n",
    "noaa dataset api use specified https://www.ncei.noaa.gov/support/access-data-service-api-user-documentation\n",
    "\n",
    "explanation of dataset lables https://www.ncei.noaa.gov/pub/data/metadata/documents/GSOYReadme.txt\n",
    "\n",
    "\n",
    "\n",
    "this uses NOAA metadata on station locations to identify stations in area and request those stations from the NOAA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "from shapely.geometry import Point, Polygon\n",
    "import re\n",
    "\n",
    "#Fire regions established the california fire science consortium \n",
    "\n",
    "region_a = Polygon([(40.467845490773,-121.22314453125),(36.08906040282,-115.7080078125),(34.836349990764,-118.5205078125),(38.980762765016,-121.88232421875)])\n",
    "region_b = Polygon([(38.632350249008,-121.71203613281),(37.508013519657,-123.42590332031),(33.062115144155,-120.13000488281),(32.06212626392,-116.24084472656),(32.80393039071,-115.95520019531),(34.432317516745,-116.61437988281),(34.739838698614,-118.13049316406),(34.757892712137,-118.56994628906)])\n",
    "region_c = Polygon([(36.012015045348,-115.47180175781),(34.794192467556,-118.43811035156),(34.39626834484,-116.15295410156),(32.080955638786,-115.66955566406),(32.619260868167,-111.62658691406),(36.047554116355,-115.18615722656)])\n",
    "region_d = Polygon([(38.692817813434,-121.71752929688),(37.621647607458,-123.36547851562),(39.511264410098,-124.90356445312),(42.251715998571,-124.94750976562),(42.316738909445,-119.36645507812),(38.949602728462,-119.25659179688),(40.604379386497,-121.25610351562),(38.881217307773,-122.02514648438)])\n",
    "regions = [region_a,region_b, region_c, region_d]\n",
    "\n",
    "\n",
    "\n",
    "#establish all stations within each region by checking for coordinates inside each region \n",
    "stations_a = []\n",
    "stations_b = []\n",
    "stations_c = []\n",
    "stations_d = []\n",
    "\n",
    "file = open('/home/devin/winternship2023/noaa_climate_data/emshr_lite (5).txt', 'r')\n",
    "count = 0\n",
    "while True:\n",
    "  line = file.readline()\n",
    "  if not line: #check for end of file \n",
    "    break\n",
    "  \n",
    "  count += 1\n",
    "  if count < 3: #insure that only the lines with data are scraped (only past the third index)\n",
    "    continue\n",
    "  \n",
    "  station_id = line[74:85]\n",
    "  station_coordinate_lat = line[272:281].strip()\n",
    "  station_coordinate_lon = line[282:292].strip()\n",
    "\n",
    "  if station_coordinate_lat == '' or station_coordinate_lon == '' or station_id.strip() == '':\n",
    "    continue\n",
    "  station_coordinate_lat = float(station_coordinate_lat)\n",
    "  station_coordinate_lon = float(station_coordinate_lon)\n",
    "  \n",
    "  station_coordinate = (station_coordinate_lat, station_coordinate_lon)\n",
    "  station_coordinate = Point(station_coordinate)\n",
    "  \n",
    "  for regional,stational in [(region_a, stations_a), (region_b, stations_b), (region_c, stations_c), (region_d, stations_d)]:\n",
    "    if regional.contains(station_coordinate):  \n",
    "      stational.append([station_id, station_coordinate])\n",
    "  \n",
    "file.close()\n",
    "\n",
    "\n",
    "\n",
    "def lat_lon_to_shapely(lat,lon): #this allows us to use basic lat and lon to create a shapely object for initial function\n",
    "  return Point(lat,lon)\n",
    "\n",
    "#takes the fire location and returns region of fire \n",
    "def find_region(fire_location):\n",
    "  for region in regions:\n",
    "    if region.contains(fire_location.centroid):\n",
    "      return region\n",
    "    # else:\n",
    "    #   return None\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#takes the region and returns a list of stations and their coordinates from metadata \n",
    "def region_station_list(region): \n",
    "  for regions, stations in [(region_a, stations_a),(region_b, stations_b),(region_c, stations_c),(region_d, stations_d)]:\n",
    "    if regions == region:\n",
    "      return stations\n",
    " \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "#takes the list of stations and fire location to return stations within a degree of distance from fire\n",
    "def closest_to_fire_center(station_list, fire_location):\n",
    "  fire_center = fire_location.centroid\n",
    "  closest_station_list = []\n",
    "  for station in station_list:\n",
    "    if station[1].distance(fire_center) < 1:\n",
    "      closest_station_list.append((station[0], station[1].distance(fire_center)))\n",
    "  closest_station_list.sort(key=lambda closest_station_list: closest_station_list[1])\n",
    "  closest_station_list = closest_station_list[:50]\n",
    "  return [x[0] for x in closest_station_list]\n",
    "\n",
    "\n",
    "\n",
    "#takes a string of closest stations and requests their data from noaa api\n",
    "def request_station_data(closest_stations):\n",
    "  closest_stations = ','.join(closest_stations)\n",
    "  \n",
    "  header = {'token': 'SXCObXMuhoovZxrVZpurQqmsHdvJWyUJ'}\n",
    "  r=requests.get(f'https://www.ncei.noaa.gov/access/services/data/v1?dataset=global-summary-of-the-year&stations={closest_stations}&&startDate=1950-01-01T00:00:00z&&endDate=2022-01-01&format=csv&bbox=-124.40959,32.534156,-114.131211,42.009518', headers=header)\n",
    "  if r.status_code != 200:\n",
    "    print(r.status_code)\n",
    "    print(r.text)\n",
    "  df = pd.read_csv(io.StringIO(r.text))\n",
    "  return df\n",
    "\n",
    "\n",
    "#takes the station data returns a dataframe row of the averaged values for year of fire \n",
    "#add a recurrance here to request more than 50 please \n",
    "def filter_station_data(station_df, fire_year):\n",
    "\n",
    "  station_df = station_df[['DATE','DP01','DP10','DP1X','DSNW','DX32','DX70','DX90','EMSN','EMXP','EMXT','PRCP', 'SNOW','TMAX',]]\n",
    "  \n",
    "  station_df = station_df.rename(columns={\"DP01\": \"PDepth>0.01in\", \"DP10\": \"PDepth>0.1in\", \"DP1X\": \"PDepth>1in\", \"DSNW\": \"SDepth>1in\", \"DX32\": \"DaysT<32d\", \"DX70\": \"DaysT>70d\", \"DX90\": \"DaysT>90d\",\n",
    "  \"EMSN\": \"HighestDaySnow\", \"EMXP\": \"HighestDayRain\", \"EMXT\": \"HighestDayTemp\", \"PRCP\": \"TotalRain\", \"SNOW\": \"TotalSnow\", \"TMAX\": \"AvgMonthMax\"})\n",
    " \n",
    "  \n",
    "  station_df = station_df[station_df['DATE'] == fire_year]\n",
    "  station_df = station_df.rename(columns = {'DATE': 'Fire_Year'})\n",
    "  #the method of filling missing values should be changed for final library touches \n",
    "  station_df = pd.DataFrame(station_df.mean()).T\n",
    "  return station_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "event_climate_data was originally meant to be the function to use on dataset but I added convert_event_data() to handle latitude and longitude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_climate_data(fire_location, fire_year): #function that returns the average local climate data for year of the fire as a row to add to dataset \n",
    "  region = find_region(fire_location)\n",
    "  if region == None:\n",
    "    return None\n",
    "  stations = region_station_list(region)\n",
    "  closest_stations = closest_to_fire_center(stations, fire_location)\n",
    "  stations_df = request_station_data(closest_stations)\n",
    "  filtered_df = filter_station_data(stations_df,fire_year)\n",
    "  return filtered_df\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ultimate applicaton of this is to input a fire's lat, lon and year to create a row of the average climate data from the 50 closest stations within a degree of distance from the fire for the year \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_event_data(lat,lon,fire_year): #this allows for direct conversion from what we have in our fire dataset \n",
    "    fire_location = lat_lon_to_shapely(lat, lon)\n",
    "    return event_climate_data(fire_location, fire_year)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "piece by piece function tests:\n",
    "- if test location is region center it should be in that region \n",
    "- region_station_list should return list of IDs and coordinates \n",
    "- closest to fire center should be less than total stations and only be IDs\n",
    "- request station data should return a a full dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in regions: #region function is accurate \n",
    "    test_location  = region.centroid\n",
    "    if find_region(test_location) != region:\n",
    "        print(f\"test failed: {test_location} should have been {region}\")\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "region = region_a\n",
    "test_stations = region_station_list(region_a) #this returns a list of stations and coordinates \n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "test_closest = closest_to_fire_center(test_stations, region_a.centroid)\n",
    "print(test_closest)\n",
    "print(str(len(test_stations)) + ' in region vs ' + str(len(test_closest)) + ' closest') #closest should contain less than test stations\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "test_df = request_station_data(test_closest) #returns dataframe of data for stations since 1950\n",
    "test_df\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "filter_station_data(test_df, 2001) #returns a row with the average data for the year "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the convert_event_data() function on each row in our fire outcome dataset\n",
    "\n",
    "convert_event_data(latitude, longitude, year)\n",
    "\n",
    "- latitude is latitude \n",
    "- longitude is latitude \n",
    "- year is the year of the event \n",
    "- returns a row of the average climate data of the closest 50 noaa stations to be added onto event datasets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_df = pd.read_csv('/home/devin/winternship2023/datasets/cal1.2.csv')\n",
    "# fire_df[\"Fire_Year\"] = fire_df[\"Fire_Year\"].apply(lambda x : pd.to_datetime(x).year)\n",
    "# display(fire_df.head())\n",
    "#add on the column names we going to add to fire dataset \n",
    "new_columns = ['PDepth>0.01in','PDepth>0.1in','PDepth>1in','SDepth>1in','DaysT<32d','DaysT>70d','DaysT>90d','HighestDaySnow','HighestDayRain','HighestDayTemp','TotalRain','TotalSnow','AvgMonthMax']\n",
    "old_columns = ['Fire_Name','Lat','Long','Fire_Year','Fire_Month','Total_area_burned(ha)','Unchanged(ha)','Low_Severity(ha)','Moderate_Severity(ha)','High_Severity(ha)','FuelTreatment','TSLF(months)']\n",
    "all_columns = old_columns + new_columns\n",
    "fire_df[new_columns] = ''\n",
    "fire_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing our process on a row of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "new_frame = pd.DataFrame(columns = all_columns)\n",
    "\n",
    "og_row = fire_df.iloc[[index]]\n",
    "display(og_row)\n",
    "\n",
    "add_on_row = convert_event_data(fire_df['Lat'][index], fire_df['Long'][index], fire_df['Fire_Year'][index])[new_columns]\n",
    "display(add_on_row) \n",
    "\n",
    "og_row.loc[index, new_columns] = add_on_row.loc[0, new_columns]\n",
    "display(og_row)\n",
    "\n",
    "new_frame.loc[index] = og_row.loc[index]\n",
    "display(new_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frame = pd.DataFrame(columns = all_columns) #where we will stack the new rows \n",
    "for index in range(len(fire_df)):\n",
    "  if find_region(lat_lon_to_shapely(fire_df['Lat'][index], fire_df['Long'][index])) == None: #if the fire is outside of our regions then we skip it\n",
    "    continue\n",
    "\n",
    "  og_row = fire_df.iloc[[index]]\n",
    "  add_on_row = convert_event_data(fire_df['Lat'][index], fire_df['Long'][index], fire_df['Fire_Year'][index])[new_columns]\n",
    "  \n",
    "  og_row.loc[index, new_columns] = add_on_row.loc[0, new_columns]\n",
    "  \n",
    "  new_frame.loc[index] = og_row.loc[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "num_columns = [ 'Lat', 'Long', 'Fire_Year','Fire_Month', 'Total_area_burned(ha)','Moderate_Severity(ha)','High_Severity(ha)','PDepth>0.01in','PDepth>0.1in','PDepth>1in','SDepth>1in','DaysT<32d','DaysT>70d','DaysT>90d','HighestDaySnow','HighestDayRain','HighestDayTemp','TotalRain','TotalSnow','AvgMonthMax']\n",
    "\n",
    "\n",
    "#replace this method of filling values please god future me I worked on documentation \n",
    "for column in num_columns:\n",
    "  new_frame[column].fillna(value= new_frame[column].mean(), inplace=True)\n",
    "\n",
    "new_frame.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frame.to_csv('../datasets/fire_climate_set.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/fire_climate_set.csv')\n",
    "display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
